#!/usr/bin/env python
"""
Train doc2vec model to be used for Newsgroup post classification using embedding

__author__ = "Hide Inada"
__copyright__ = "Copyright 2018, Hide Inada"
__license__ = "The MIT License"
__email__ = "hideyuki@gmail.com"
"""

import os
import logging
import argparse

from pathlib import Path
import numpy as np

import gensim
from gensim.models.doc2vec import Doc2Vec

from project.normalize_words import normalize_words
from project.load_text_data import load_text_from_files
from project.text_to_id import map_label_to_id
from project.text_to_id import map_text_list_to_word_list
from project.text_to_id import map_text_to_word_id
from project.text_to_id import map_word_list_to_vocabulary


MODEL_FILE = "/tmp/tp/doc2vec_newsgroup.model"

log = logging.getLogger(__name__)
logging.basicConfig(level=os.environ.get("LOGLEVEL", "INFO"))  # Change the 2nd arg to INFO to suppress debug logging

# Example of data dir:
# ../../../../ai/dataset/20/20newsgroups_fromto_only/20news-18828
# Specify this with --data_dir option on the command line

def train(data_dir=None):
    """Train the model.

    Parameters
    ----------
    data_dir: str
        Directory where the data is stored.

    raises
    -------
    ValueError
        If data_dir is not set.
    """
    if data_dir is None:
        raise ValueError("data_dir is not set.")

    # Load text data
    (x_train_text, y_train_labels), (x_test_text, y_test_labels) = \
        load_text_from_files(Path(data_dir), test_dataset_ratio=0.2, errors='ignore')

    num_files_train = len(x_train_text)
    num_labels_train = len(set(y_train_labels))

    num_files_test = len(x_test_text)
    num_labels_test = len(set(y_test_labels))

    log.info("Number of labels found in training dataset: %d" % (num_labels_train))
    log.info("Number of posts found in training dataset: %d" % (num_files_train))

    log.info("Number of labels found in test dataset: %d" % (num_labels_test))
    log.info("Number of posts found in test dataset: %d" % (num_files_test))

    assert num_labels_train == num_labels_test

    # Break up entire text to words
    corpus = []
    for i, text in enumerate(x_train_text):
        word_list = normalize_words(text)
        tag_list = ["_TRAIN_ID%d_" % (i)]
        tagged_doc = gensim.models.doc2vec.TaggedDocument(word_list, tag_list)
        corpus.append(tagged_doc)

    model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=40)
    model.build_vocab(corpus)
    log.info("Build completed")

    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)

    model_path = Path(MODEL_FILE)
    model_dir = model_path.parent
    if model_dir.exists() is False:
        model_dir.mkdir(parents=True, exist_ok=True)

    model.save(MODEL_FILE)

def main():
    """Defines an application's main functionality"""

    parser = argparse.ArgumentParser(description='Newsgroup post classifier')
    parser.add_argument('--data_dir',
                        type=str,
                        help="Data directory")

    args = parser.parse_args()
    data_dir = args.data_dir

    train(data_dir=data_dir)


if __name__ == "__main__":
    main()
